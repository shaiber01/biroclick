"""Tests that enforce plan reviewer behavior and dependency validation."""

from unittest.mock import patch
import json


class TestPlanReviewerLLMCalls:
    """Verify plan reviewer LLM interactions."""

    def test_plan_reviewer_node_calls_llm_with_correct_agent_name(self, base_state):
        """plan_reviewer_node must call LLM with agent_name='plan_reviewer'."""
        from src.agents.planning import plan_reviewer_node

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ) as mock:
            result = plan_reviewer_node(base_state)

        # Verify LLM was called
        assert mock.called, "LLM should be called for valid plan"
        call_kwargs = mock.call_args.kwargs
        system_prompt = call_kwargs.get("system_prompt", "")
        assert len(system_prompt) > 100, f"System prompt too short ({len(system_prompt)} chars)"
        assert call_kwargs.get("agent_name") == "plan_reviewer", (
            "Expected agent_name='plan_reviewer', "
            f"got '{call_kwargs.get('agent_name')}'"
        )
        
        # Verify return value structure
        assert "workflow_phase" in result, "Result must include workflow_phase"
        assert result["workflow_phase"] == "plan_review", f"Expected workflow_phase='plan_review', got '{result['workflow_phase']}'"
        assert "last_plan_review_verdict" in result, "Result must include last_plan_review_verdict"
        assert result["last_plan_review_verdict"] == "approve", f"Expected verdict='approve', got '{result['last_plan_review_verdict']}'"
        
        # Verify plan is included in user_content
        user_content = call_kwargs.get("user_content", "")
        assert "REPRODUCTION PLAN TO REVIEW" in user_content, "User content should include plan review section"
        assert '"paper_id": "test"' in user_content, "Plan should be serialized in user content"
        
        # Verify replan_count is NOT incremented for approve
        assert "replan_count" not in result or result.get("replan_count") == base_state.get("replan_count", 0), (
            "replan_count should not be incremented when verdict is 'approve'"
        )

    def test_plan_reviewer_handles_llm_error(self, base_state):
        """plan_reviewer should fail-closed (needs_revision) on LLM failure.
        
        This is the correct defensive behavior - reviewers should not auto-approve
        when they cannot actually review. The component uses default_verdict="needs_revision"
        which is safer than auto-approve.
        """
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["f1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0  # Set initial count so we can verify increment

        with patch(
            "src.agents.planning.call_agent_with_metrics", side_effect=Exception("LLM Fail")
        ):
            result = plan_reviewer_node(base_state)

        # Fail-closed: needs_revision is safer than auto-approve when review cannot be performed
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected fail-closed (needs_revision) on LLM error, got '{result['last_plan_review_verdict']}'"
        )
        assert result["workflow_phase"] == "plan_review", "Workflow phase should be set"
        # replan_count SHOULD be incremented for LLM rejection (not a blocking structural issue)
        assert result.get("replan_count") == 1, (
            f"replan_count should be incremented on LLM error rejection, got {result.get('replan_count')}"
        )
        # Should have planner_feedback set
        assert "planner_feedback" in result, "Should have planner_feedback on rejection"
    
    def test_plan_reviewer_includes_assumptions_in_user_content(self, base_state):
        """plan_reviewer should include assumptions in user_content when calling LLM."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["assumptions"] = {
            "material": "gold",
            "wavelength": 650,
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ) as mock:
            plan_reviewer_node(base_state)

        user_content = mock.call_args.kwargs.get("user_content", "")
        assert "ASSUMPTIONS" in user_content, "User content should include assumptions section"
        assert '"material": "gold"' in user_content, "Assumptions should be serialized in user content"
        assert '"wavelength": 650' in user_content, "All assumption values should be included"
    
    def test_plan_reviewer_handles_missing_assumptions(self, base_state):
        """plan_reviewer should handle missing assumptions gracefully."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        # Explicitly remove assumptions if present
        if "assumptions" in base_state:
            del base_state["assumptions"]

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ) as mock:
            result = plan_reviewer_node(base_state)

        # Should still work without assumptions
        assert result["last_plan_review_verdict"] == "approve"
        user_content = mock.call_args.kwargs.get("user_content", "")
        # Assumptions section should not be present if assumptions is None
        if "assumptions" not in base_state:
            # User content should still contain plan
            assert "REPRODUCTION PLAN TO REVIEW" in user_content


class TestBusinessLogic:
    """Test that planning business logic rules are enforced."""

    def test_plan_reviewer_rejects_empty_stages(self, base_state):
        """plan_reviewer_node should reject plans with no stages."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Empty Plan",
            "stages": [],
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for empty stages, got '{result['last_plan_review_verdict']}'"
        )
        assert result["workflow_phase"] == "plan_review", "Workflow phase should be set"
        feedback = result.get("planner_feedback", "")
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
        assert "no stages" in feedback.lower() or "at least one stage" in feedback.lower(), (
            f"Feedback should mention empty stages issue, got: {feedback}"
        )
        # Verify LLM is NOT called for blocking issues
        assert "must contain at least one stage" in feedback or "no stages" in feedback.lower(), (
            "Should detect blocking issue without LLM call"
        )
    
    def test_plan_reviewer_rejects_none_stages(self, base_state):
        """plan_reviewer_node should reject plans with None stages."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "None Stages Plan",
            "stages": None,
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for None stages, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_rejects_none_plan(self, base_state):
        """plan_reviewer_node should handle None plan gracefully."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = None

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for None plan, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "PLAN_ISSUE" in feedback or "no stages" in feedback.lower(), (
            f"Feedback should indicate plan issue, got: {feedback}"
        )
    
    def test_plan_reviewer_rejects_missing_plan_key(self, base_state):
        """plan_reviewer_node should handle missing plan key."""
        from src.agents.planning import plan_reviewer_node

        if "plan" in base_state:
            del base_state["plan"]

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for missing plan, got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_rejects_stages_without_targets(self, base_state):
        """plan_reviewer_node should reject stages without targets."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Bad Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": [],
                    "dependencies": [],
                }
            ],
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for stage without targets, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "Stage 's1' has no targets" in feedback or "no targets" in feedback.lower(), (
            f"Feedback should mention stage s1 has no targets, got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_rejects_stages_without_targets_or_target_details(self, base_state):
        """plan_reviewer_node should reject stages with neither targets nor target_details."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Bad Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": [],
                    "target_details": [],
                    "dependencies": [],
                }
            ],
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for stage without targets or target_details, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "no targets" in feedback.lower(), (
            f"Feedback should mention no targets, got: {feedback}"
        )
    
    def test_plan_reviewer_accepts_stages_with_target_details_only(self, base_state):
        """plan_reviewer_node should accept stages with target_details but no targets."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Good Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": [],
                    "target_details": [{"figure_id": "Fig1"}],
                    "dependencies": [],
                }
            ],
            "targets": [],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Should not be rejected for missing targets if target_details exists
        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for stage with target_details, got '{result['last_plan_review_verdict']}'"
        )
    
    def test_plan_reviewer_rejects_stages_with_none_targets(self, base_state):
        """plan_reviewer_node should reject stages with None targets."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Bad Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": None,
                    "dependencies": [],
                }
            ],
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for None targets, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "no targets" in feedback.lower() or "Stage 's1'" in feedback, (
            f"Feedback should mention missing targets, got: {feedback}"
        )

    def test_plan_reviewer_increments_replan_count(self, base_state):
        """plan_reviewer should increment replan_count on rejection."""
        from src.agents.planning import plan_reviewer_node

        base_state["replan_count"] = 0
        base_state["plan"] = {"stages": []}  # Force rejection

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject empty plan"
        # For blocking issues, replan_count is only incremented if it was already in state
        # Since we set it to 0, it should be incremented
        assert result.get("replan_count") == 1, (
            f"Expected replan_count=1 after rejection, got {result.get('replan_count')}"
        )
    
    def test_plan_reviewer_increments_replan_count_from_zero(self, base_state):
        """plan_reviewer should increment replan_count from 0 on LLM rejection."""
        from src.agents.planning import plan_reviewer_node

        base_state["replan_count"] = 0
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        # LLM rejects the plan
        mock_response = {
            "verdict": "needs_revision",
            "issues": [{"severity": "major", "description": "Plan is incomplete"}],
            "summary": "Plan needs revision",
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject plan"
        # For LLM rejections, replan_count should be incremented even if starting from 0
        assert result.get("replan_count") == 1, (
            f"Expected replan_count=1 after LLM rejection, got {result.get('replan_count')}"
        )
    
    def test_plan_reviewer_does_not_increment_replan_count_when_not_in_state_for_blocking_issue(self, base_state):
        """plan_reviewer should not add replan_count if not in state for blocking issues."""
        from src.agents.planning import plan_reviewer_node

        # Remove replan_count from state
        if "replan_count" in base_state:
            del base_state["replan_count"]
        
        base_state["plan"] = {"stages": []}  # Force rejection (blocking issue)

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject empty plan"
        # For blocking issues, replan_count should NOT be added if it wasn't in state
        assert "replan_count" not in result, (
            f"replan_count should not be added for blocking issues when not in state, got {result.get('replan_count')}"
        )

    def test_plan_reviewer_max_replans(self, base_state):
        """plan_reviewer should not increment replan_count beyond max."""
        from src.agents.planning import plan_reviewer_node

        base_state["replan_count"] = 3
        base_state["runtime_config"] = {"max_replans": 3}
        base_state["plan"] = {"stages": []}  # Force rejection

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject empty plan"
        assert result.get("replan_count") == 3, (
            f"Expected replan_count=3 (at max), got {result.get('replan_count')}"
        )
    
    def test_plan_reviewer_respects_max_replans_from_config(self, base_state):
        """plan_reviewer should respect max_replans from runtime_config."""
        from src.agents.planning import plan_reviewer_node

        base_state["replan_count"] = 1
        base_state["runtime_config"] = {"max_replans": 2}
        base_state["plan"] = {"stages": []}  # Force rejection

        result = plan_reviewer_node(base_state)
        assert result.get("replan_count") == 2, (
            f"Expected replan_count=2 (incremented to max), got {result.get('replan_count')}"
        )
        
        # Try again - should stay at max
        base_state["replan_count"] = 2
        result = plan_reviewer_node(base_state)
        assert result.get("replan_count") == 2, (
            f"Expected replan_count=2 (at max), got {result.get('replan_count')}"
        )
    
    def test_plan_reviewer_uses_default_max_replans_when_not_in_config(self, base_state):
        """plan_reviewer should use default MAX_REPLANS when not in runtime_config."""
        from src.agents.planning import plan_reviewer_node
        from schemas.state import MAX_REPLANS

        base_state["replan_count"] = MAX_REPLANS - 1
        base_state["runtime_config"] = {}  # No max_replans specified
        base_state["plan"] = {"stages": []}  # Force rejection

        result = plan_reviewer_node(base_state)
        assert result.get("replan_count") == MAX_REPLANS, (
            f"Expected replan_count={MAX_REPLANS} (default max), got {result.get('replan_count')}"
        )
        
        # Try again - should stay at max
        base_state["replan_count"] = MAX_REPLANS
        result = plan_reviewer_node(base_state)
        assert result.get("replan_count") == MAX_REPLANS, (
            f"Expected replan_count={MAX_REPLANS} (at max), got {result.get('replan_count')}"
        )
    
    def test_plan_reviewer_does_not_increment_on_approve(self, base_state):
        """plan_reviewer should not increment replan_count when verdict is approve."""
        from src.agents.planning import plan_reviewer_node

        base_state["replan_count"] = 0
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", "Should approve valid plan"
        # replan_count should not be incremented on approve
        assert "replan_count" not in result or result.get("replan_count") == 0, (
            f"replan_count should not be incremented on approve, got {result.get('replan_count')}"
        )


class TestCircularDependencyDetection:
    """Verify plan_reviewer correctly detects dependency cycles."""

    def test_plan_reviewer_detects_simple_cycle(self, base_state):
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Cyclic Plan",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["stage_b"],
                },
                {
                    "stage_id": "stage_b",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": ["stage_a"],
                },
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for circular dependency, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "circular" in feedback.lower() or "cycle" in feedback.lower(), (
            f"Feedback should mention circular dependency, got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
        # Verify cycle description includes stage names
        assert "stage_a" in feedback.lower() or "stage_b" in feedback.lower(), (
            f"Feedback should mention cycle stages, got: {feedback}"
        )

    def test_plan_reviewer_detects_self_dependency(self, base_state):
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Self-Dependent Plan",
            "stages": [
                {
                    "stage_id": "stage_0",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["stage_0"],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for self-dependency, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "depends on itself" in feedback.lower() or "self" in feedback.lower(), (
            f"Feedback should mention self-dependency, got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
        assert "stage_0" in feedback.lower(), (
            f"Feedback should mention stage_0, got: {feedback}"
        )

    def test_plan_reviewer_detects_transitive_cycle(self, base_state):
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Transitive Cycle",
            "stages": [
                {
                    "stage_id": "a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["c"],
                },
                {
                    "stage_id": "b",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": ["a"],
                },
                {
                    "stage_id": "c",
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig2"],
                    "dependencies": ["b"],
                },
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for transitive cycle, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "circular" in feedback.lower() or "cycle" in feedback.lower(), (
            f"Feedback should mention cycle, got: {feedback}"
        )
        # Verify cycle includes all stages in the cycle
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_detects_multiple_cycles(self, base_state):
        """plan_reviewer should detect multiple independent cycles."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Cycles",
            "stages": [
                # First cycle: a -> b -> a
                {
                    "stage_id": "a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["b"],
                },
                {
                    "stage_id": "b",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": ["a"],
                },
                # Second cycle: c -> d -> c
                {
                    "stage_id": "c",
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig3"],
                    "dependencies": ["d"],
                },
                {
                    "stage_id": "d",
                    "stage_type": "PARAMETER_SWEEP",
                    "targets": ["Fig4"],
                    "dependencies": ["c"],
                },
            ],
            "targets": [
                {"figure_id": "Fig1"},
                {"figure_id": "Fig2"},
                {"figure_id": "Fig3"},
                {"figure_id": "Fig4"},
            ],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for multiple cycles, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "circular" in feedback.lower() or "cycle" in feedback.lower(), (
            f"Feedback should mention cycles, got: {feedback}"
        )
        # Should detect both cycles
        assert feedback.count("circular") >= 1 or feedback.count("cycle") >= 1, (
            f"Feedback should mention multiple cycles, got: {feedback}"
        )

    def test_plan_reviewer_rejects_dependency_on_missing_stage(self, base_state):
        """plan_reviewer should reject dependencies that point to non-existent stages."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Broken Dependency",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["stage_b"],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for missing dependency, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "depends on missing stage" in feedback.lower() or "missing stage" in feedback.lower(), (
            f"Feedback should mention missing stage dependency, got: {feedback}"
        )
        assert "stage_a" in feedback.lower() or "stage_b" in feedback.lower(), (
            f"Feedback should mention stage names, got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_rejects_multiple_missing_dependencies(self, base_state):
        """plan_reviewer should detect all missing dependencies."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Missing Dependencies",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": ["missing_1", "missing_2"],
                },
                {
                    "stage_id": "stage_b",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": ["missing_3"],
                },
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for missing dependencies, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "missing stage" in feedback.lower(), (
            f"Feedback should mention missing stages, got: {feedback}"
        )
        # Should mention multiple missing stages
        assert feedback.count("missing") >= 2 or feedback.count("depends") >= 2, (
            f"Feedback should mention multiple missing dependencies, got: {feedback}"
        )
    
    def test_plan_reviewer_rejects_empty_dependency_list(self, base_state):
        """plan_reviewer should handle empty dependency lists correctly."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Empty Dependencies",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Empty dependencies should be valid
        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for valid plan with empty dependencies, got '{result['last_plan_review_verdict']}'"
        )
    
    def test_plan_reviewer_rejects_none_dependencies(self, base_state):
        """plan_reviewer should handle None dependencies."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "None Dependencies",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": None,
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        # Should handle None gracefully - code uses .get("dependencies", []) which returns [] for None
        # So this should not cause an error, but let's verify
        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # None dependencies should be treated as empty list
        assert result["last_plan_review_verdict"] in ["approve", "needs_revision"], (
            f"Should handle None dependencies gracefully, got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_rejects_duplicate_stage_ids(self, base_state):
        """plan_reviewer should reject plans with duplicate stage IDs."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Duplicate Stages",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                },
                {
                    "stage_id": "stage_a",  # Duplicate ID
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": [],
                },
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for duplicate stage IDs, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "duplicate stage id" in feedback.lower() or "duplicate" in feedback.lower(), (
            f"Feedback should mention duplicate stage ID, got: {feedback}"
        )
        assert "stage_a" in feedback.lower(), (
            f"Feedback should mention duplicate stage ID 'stage_a', got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_rejects_multiple_duplicate_stage_ids(self, base_state):
        """plan_reviewer should detect multiple duplicate stage IDs."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Duplicates",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                },
                {
                    "stage_id": "stage_a",  # First duplicate
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": [],
                },
                {
                    "stage_id": "stage_b",
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig3"],
                    "dependencies": [],
                },
                {
                    "stage_id": "stage_b",  # Second duplicate
                    "stage_type": "PARAMETER_SWEEP",
                    "targets": ["Fig4"],
                    "dependencies": [],
                },
            ],
            "targets": [
                {"figure_id": "Fig1"},
                {"figure_id": "Fig2"},
                {"figure_id": "Fig3"},
                {"figure_id": "Fig4"},
            ],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for multiple duplicates, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "duplicate" in feedback.lower(), (
            f"Feedback should mention duplicates, got: {feedback}"
        )
        # Should mention both duplicate IDs
        assert ("stage_a" in feedback.lower() and "stage_b" in feedback.lower()) or feedback.count("duplicate") >= 2, (
            f"Feedback should mention multiple duplicates, got: {feedback}"
        )

    def test_plan_reviewer_rejects_missing_stage_id(self, base_state):
        """plan_reviewer should reject stages with missing IDs."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Missing ID",
            "stages": [
                {
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for missing stage_id, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "missing 'stage_id'" in feedback.lower() or "missing stage_id" in feedback.lower(), (
            f"Feedback should mention missing stage_id, got: {feedback}"
        )
        assert "PLAN_ISSUE" in feedback, f"Feedback should contain 'PLAN_ISSUE', got: {feedback}"
    
    def test_plan_reviewer_rejects_empty_stage_id(self, base_state):
        """plan_reviewer should reject stages with empty string stage_id."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Empty Stage ID",
            "stages": [
                {
                    "stage_id": "",  # Empty string
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for empty stage_id, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "missing 'stage_id'" in feedback.lower() or "missing stage_id" in feedback.lower(), (
            f"Feedback should mention missing stage_id, got: {feedback}"
        )
    
    def test_plan_reviewer_rejects_none_stage_id(self, base_state):
        """plan_reviewer should reject stages with None stage_id."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "None Stage ID",
            "stages": [
                {
                    "stage_id": None,
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for None stage_id, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "missing 'stage_id'" in feedback.lower() or "missing stage_id" in feedback.lower(), (
            f"Feedback should mention missing stage_id, got: {feedback}"
        )
    
    def test_plan_reviewer_rejects_multiple_stages_with_missing_ids(self, base_state):
        """plan_reviewer should detect all stages with missing IDs."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Missing IDs",
            "stages": [
                {
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                },
                {
                    "stage_id": "valid_id",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig2"],
                    "dependencies": [],
                },
                {
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig3"],
                    "dependencies": [],
                },
            ],
            "targets": [
                {"figure_id": "Fig1"},
                {"figure_id": "Fig2"},
                {"figure_id": "Fig3"},
            ],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for multiple missing IDs, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "missing 'stage_id'" in feedback.lower() or "missing stage_id" in feedback.lower(), (
            f"Feedback should mention missing stage_id, got: {feedback}"
        )
        # Should detect multiple missing IDs
        assert feedback.count("missing") >= 2 or feedback.count("stage_id") >= 2, (
            f"Feedback should mention multiple missing stage IDs, got: {feedback}"
        )


class TestVerdictNormalization:
    """Test verdict normalization logic in plan_reviewer_node."""

    def test_plan_reviewer_normalizes_pass_to_approve(self, base_state):
        """plan_reviewer should normalize 'pass' verdict to 'approve'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        # LLM returns "pass" instead of "approve"
        mock_response = {"verdict": "pass", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' (normalized from 'pass'), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_normalizes_approved_to_approve(self, base_state):
        """plan_reviewer should normalize 'approved' verdict to 'approve'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "approved", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' (normalized from 'approved'), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_normalizes_accept_to_approve(self, base_state):
        """plan_reviewer should normalize 'accept' verdict to 'approve'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "accept", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' (normalized from 'accept'), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_normalizes_reject_to_needs_revision(self, base_state):
        """plan_reviewer should normalize 'reject' verdict to 'needs_revision'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        mock_response = {"verdict": "reject", "issues": [{"severity": "major", "description": "Plan incomplete"}], "summary": "Rejected"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (normalized from 'reject'), got '{result['last_plan_review_verdict']}'"
        )
        # Also verify replan_count was incremented
        assert result.get("replan_count") == 1, "replan_count should be incremented on rejection"

    def test_plan_reviewer_normalizes_revision_needed_to_needs_revision(self, base_state):
        """plan_reviewer should normalize 'revision_needed' verdict to 'needs_revision'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        mock_response = {"verdict": "revision_needed", "issues": [], "summary": "Needs work"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (normalized from 'revision_needed'), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_normalizes_needs_work_to_needs_revision(self, base_state):
        """plan_reviewer should normalize 'needs_work' verdict to 'needs_revision'."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        mock_response = {"verdict": "needs_work", "issues": [], "summary": "Needs work"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (normalized from 'needs_work'), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_defaults_to_needs_revision_for_unknown_verdict(self, base_state):
        """plan_reviewer should default to 'needs_revision' for unknown verdicts (fail-closed)."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        # Unknown verdict value
        mock_response = {"verdict": "maybe_ok", "issues": [], "summary": "Uncertain"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (fail-closed for unknown verdict), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_defaults_to_needs_revision_for_missing_verdict(self, base_state):
        """plan_reviewer should default to 'needs_revision' when verdict is missing."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        # Missing verdict key entirely
        mock_response = {"issues": [], "summary": "Review done"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (for missing verdict), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_defaults_to_needs_revision_for_none_verdict(self, base_state):
        """plan_reviewer should default to 'needs_revision' when verdict is None."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        # verdict is None
        mock_response = {"verdict": None, "issues": [], "summary": "Review done"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (for None verdict), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_defaults_to_needs_revision_for_empty_string_verdict(self, base_state):
        """plan_reviewer should default to 'needs_revision' when verdict is empty string."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        # verdict is empty string
        mock_response = {"verdict": "", "issues": [], "summary": "Review done"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' (for empty string verdict), got '{result['last_plan_review_verdict']}'"
        )


class TestAskUserEscalation:
    """Test ask_user escalation when max replans is reached."""

    def test_plan_reviewer_escalates_to_user_at_max_replans(self, base_state):
        """plan_reviewer should escalate to ask_user when max replans reached."""
        from src.agents.planning import plan_reviewer_node
        from schemas.state import MAX_REPLANS

        # Set replan_count to max-1 so the rejection pushes it to max
        base_state["replan_count"] = MAX_REPLANS - 1
        base_state["runtime_config"] = {}  # Use default MAX_REPLANS
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "needs_revision", "issues": [{"severity": "major", "description": "Issues"}], "summary": "Needs work", "feedback": "Fix these issues"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", "Should still be needs_revision"
        assert result.get("replan_count") == MAX_REPLANS, f"Should be at max ({MAX_REPLANS})"
        assert result.get("ask_user_trigger") == "replan_limit", (
            f"Should trigger ask_user with 'replan_limit', got '{result.get('ask_user_trigger')}'"
        )
        assert result.get("awaiting_user_input") is True, "Should be awaiting user input"
        assert "pending_user_questions" in result, "Should have pending_user_questions"
        assert len(result["pending_user_questions"]) > 0, "Should have at least one question"
        # Verify question mentions the limit
        question = result["pending_user_questions"][0]
        assert f"{MAX_REPLANS}/{MAX_REPLANS}" in question, f"Question should mention replan limit, got: {question}"
        # Verify question contains feedback
        assert "Fix these issues" in question or "feedback" in question.lower(), f"Question should include feedback, got: {question}"

    def test_plan_reviewer_escalates_to_user_at_custom_max_replans(self, base_state):
        """plan_reviewer should respect custom max_replans from runtime_config."""
        from src.agents.planning import plan_reviewer_node

        custom_max = 2
        base_state["replan_count"] = custom_max - 1  # At max-1
        base_state["runtime_config"] = {"max_replans": custom_max}
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "needs_revision", "issues": [], "summary": "Needs work"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result.get("replan_count") == custom_max, f"Should be at custom max ({custom_max})"
        assert result.get("ask_user_trigger") == "replan_limit", "Should escalate at custom max"
        assert result.get("awaiting_user_input") is True, "Should be awaiting user input"

    def test_plan_reviewer_does_not_escalate_before_max_replans(self, base_state):
        """plan_reviewer should NOT escalate before max replans is reached."""
        from src.agents.planning import plan_reviewer_node
        from schemas.state import MAX_REPLANS

        # Set to less than max-1
        base_state["replan_count"] = 0
        base_state["runtime_config"] = {}
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "needs_revision", "issues": [], "summary": "Needs work"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result.get("replan_count") == 1, "Should increment to 1"
        assert "ask_user_trigger" not in result or result.get("ask_user_trigger") is None, (
            "Should NOT escalate before max replans"
        )
        assert result.get("awaiting_user_input") is not True, "Should NOT be awaiting user input"

    def test_plan_reviewer_escalation_includes_last_node_before_ask_user(self, base_state):
        """plan_reviewer escalation should set last_node_before_ask_user."""
        from src.agents.planning import plan_reviewer_node
        from schemas.state import MAX_REPLANS

        base_state["replan_count"] = MAX_REPLANS - 1
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "needs_revision", "issues": [], "summary": "Needs work"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result.get("last_node_before_ask_user") == "plan_review", (
            f"Expected last_node_before_ask_user='plan_review', got '{result.get('last_node_before_ask_user')}'"
        )


class TestPlannerFeedback:
    """Test planner_feedback handling in plan_reviewer_node."""

    def test_plan_reviewer_sets_planner_feedback_on_llm_rejection(self, base_state):
        """plan_reviewer should set planner_feedback from LLM response on rejection."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        feedback_text = "The plan needs better target coverage and clearer dependencies."
        mock_response = {
            "verdict": "needs_revision",
            "issues": [{"severity": "major", "description": "Incomplete"}],
            "summary": "Plan needs work",
            "feedback": feedback_text,
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result.get("planner_feedback") == feedback_text, (
            f"Expected planner_feedback='{feedback_text}', got '{result.get('planner_feedback')}'"
        )

    def test_plan_reviewer_uses_summary_as_fallback_for_planner_feedback(self, base_state):
        """plan_reviewer should fall back to summary when feedback is missing."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        summary_text = "Plan needs improvements in target coverage"
        mock_response = {
            "verdict": "needs_revision",
            "issues": [],
            "summary": summary_text,
            # No "feedback" key
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result.get("planner_feedback") == summary_text, (
            f"Expected planner_feedback='{summary_text}' (fallback from summary), got '{result.get('planner_feedback')}'"
        )

    def test_plan_reviewer_sets_empty_planner_feedback_when_both_missing(self, base_state):
        """plan_reviewer should set empty string when both feedback and summary are missing."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["replan_count"] = 0

        mock_response = {
            "verdict": "needs_revision",
            "issues": [],
            # No "feedback" or "summary" keys
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert "planner_feedback" in result, "planner_feedback should be set on rejection"
        assert result["planner_feedback"] == "", (
            f"Expected empty planner_feedback when both missing, got '{result.get('planner_feedback')}'"
        )

    def test_plan_reviewer_does_not_set_planner_feedback_on_approval(self, base_state):
        """plan_reviewer should NOT set planner_feedback when verdict is approve."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {
            "verdict": "approve",
            "issues": [],
            "summary": "Plan looks good",
            "feedback": "Some optional feedback",
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert "planner_feedback" not in result, (
            f"planner_feedback should NOT be set on approval, got '{result.get('planner_feedback')}'"
        )


class TestContextCheckBehavior:
    """Test with_context_check decorator behavior in plan_reviewer_node."""

    def test_plan_reviewer_returns_empty_when_awaiting_user_input(self, base_state):
        """plan_reviewer should return empty dict when already awaiting user input."""
        from src.agents.planning import plan_reviewer_node

        base_state["awaiting_user_input"] = True
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [{"stage_id": "s1", "stage_type": "MATERIAL_VALIDATION", "targets": ["Fig1"], "dependencies": []}],
        }

        result = plan_reviewer_node(base_state)

        # The decorator should return empty dict to avoid modifying state
        assert result == {}, f"Expected empty dict when awaiting user input, got {result}"


class TestComplexScenarios:
    """Test complex scenarios and edge cases."""

    def test_plan_reviewer_handles_valid_plan_with_multiple_stages(self, base_state):
        """plan_reviewer should approve valid plan with multiple stages and dependencies."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Valid Multi-Stage Plan",
            "stages": [
                {
                    "stage_id": "stage_0",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["material_gold"],
                    "dependencies": [],
                },
                {
                    "stage_id": "stage_1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": ["stage_0"],
                },
                {
                    "stage_id": "stage_2",
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig2"],
                    "dependencies": ["stage_1"],
                },
            ],
            "targets": [
                {"figure_id": "Fig1"},
                {"figure_id": "Fig2"},
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for valid plan, got '{result['last_plan_review_verdict']}'"
        )
        assert result["workflow_phase"] == "plan_review", "Workflow phase should be set"
    
    def test_plan_reviewer_handles_combined_issues(self, base_state):
        """plan_reviewer should detect multiple types of issues in one plan."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Issues Plan",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": [],  # Missing targets
                    "dependencies": ["missing_stage"],  # Missing dependency
                },
                {
                    "stage_id": "stage_a",  # Duplicate ID
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": [],
                },
                {
                    # Missing stage_id
                    "stage_type": "ARRAY_SYSTEM",
                    "targets": ["Fig2"],
                    "dependencies": [],
                },
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for plan with multiple issues, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        # Should detect multiple issues
        assert feedback.count("PLAN_ISSUE") >= 3 or len([i for i in feedback.split("\n") if "PLAN_ISSUE" in i]) >= 3, (
            f"Feedback should mention multiple issues, got: {feedback}"
        )
    
    def test_plan_reviewer_feedback_format_for_blocking_issues(self, base_state):
        """plan_reviewer should format feedback correctly for blocking issues."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Blocking Issues Plan",
            "stages": [
                {
                    "stage_id": "stage_a",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": [],
                    "dependencies": [],
                }
            ],
            "targets": [],
        }

        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject plan"
        feedback = result.get("planner_feedback", "")
        
        # Feedback should be a string
        assert isinstance(feedback, str), f"Feedback should be a string, got {type(feedback)}"
        assert len(feedback) > 0, "Feedback should not be empty"
        
        # Should contain structured information
        assert "PLAN_ISSUE" in feedback, "Feedback should contain PLAN_ISSUE marker"
    
    def test_plan_reviewer_workflow_phase_is_always_set(self, base_state):
        """plan_reviewer should always set workflow_phase in result."""
        from src.agents.planning import plan_reviewer_node

        # Test with valid plan
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert "workflow_phase" in result, "Result must include workflow_phase"
        assert result["workflow_phase"] == "plan_review", (
            f"Expected workflow_phase='plan_review', got '{result['workflow_phase']}'"
        )
        
        # Test with invalid plan
        base_state["plan"] = {"stages": []}
        result = plan_reviewer_node(base_state)
        assert "workflow_phase" in result, "Result must include workflow_phase even for invalid plan"
        assert result["workflow_phase"] == "plan_review", (
            f"Expected workflow_phase='plan_review', got '{result['workflow_phase']}'"
        )
    
    def test_plan_reviewer_handles_malformed_stage_structure(self, base_state):
        """plan_reviewer should handle malformed stage structures gracefully."""
        from src.agents.planning import plan_reviewer_node

        # Stage is not a dict
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Malformed Plan",
            "stages": ["not_a_dict"],  # Invalid: should be list of dicts
            "targets": [],
        }

        # Should not crash, should detect issue
        result = plan_reviewer_node(base_state)
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for malformed plan, got '{result['last_plan_review_verdict']}'"
        )
    
    def test_plan_reviewer_validates_all_stages_before_llm_call(self, base_state):
        """plan_reviewer should validate all stages before calling LLM."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Partially Invalid Plan",
            "stages": [
                {
                    "stage_id": "valid_stage",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                },
                {
                    "stage_id": "invalid_stage",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": [],  # Missing targets
                    "dependencies": [],
                },
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        with patch(
            "src.agents.planning.call_agent_with_metrics"
        ) as mock_llm:
            result = plan_reviewer_node(base_state)

        # Should detect blocking issue and NOT call LLM
        assert result["last_plan_review_verdict"] == "needs_revision", "Should reject plan"
        assert not mock_llm.called, "LLM should not be called when blocking issues exist"
        feedback = result.get("planner_feedback", "")
        assert "invalid_stage" in feedback.lower() or "no targets" in feedback.lower(), (
            f"Feedback should mention invalid stage, got: {feedback}"
        )


class TestStageTypeValidation:
    """Test validation of stage_type values."""

    def test_plan_reviewer_accepts_valid_stage_types(self, base_state):
        """plan_reviewer should accept all valid stage types."""
        from src.agents.planning import plan_reviewer_node

        valid_stage_types = [
            "MATERIAL_VALIDATION",
            "SINGLE_STRUCTURE",
            "ARRAY_SYSTEM",
            "PARAMETER_SWEEP",
        ]

        for stage_type in valid_stage_types:
            base_state["plan"] = {
                "paper_id": "test",
                "title": f"Test Plan with {stage_type}",
                "stages": [
                    {
                        "stage_id": f"stage_{stage_type}",
                        "stage_type": stage_type,
                        "targets": ["Fig1"],
                        "dependencies": [],
                    }
                ],
                "targets": [{"figure_id": "Fig1"}],
            }

            mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

            with patch(
                "src.agents.planning.call_agent_with_metrics", return_value=mock_response
            ):
                result = plan_reviewer_node(base_state)

            assert result["last_plan_review_verdict"] == "approve", (
                f"Expected 'approve' for valid stage_type '{stage_type}', got '{result['last_plan_review_verdict']}'"
            )


class TestPlanStructureEdgeCases:
    """Test edge cases in plan structure validation."""

    def test_plan_reviewer_handles_stage_with_very_long_id(self, base_state):
        """plan_reviewer should handle stages with very long IDs."""
        from src.agents.planning import plan_reviewer_node

        long_id = "stage_" + "a" * 500  # 506 character ID
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Long ID Plan",
            "stages": [
                {
                    "stage_id": long_id,
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Should not crash with long ID
        assert result["workflow_phase"] == "plan_review", "Should complete with long ID"

    def test_plan_reviewer_handles_stage_with_special_characters_in_id(self, base_state):
        """plan_reviewer should handle stages with special characters in IDs."""
        from src.agents.planning import plan_reviewer_node

        special_id = "stage-1_2.3:test"
        base_state["plan"] = {
            "paper_id": "test",
            "title": "Special ID Plan",
            "stages": [
                {
                    "stage_id": special_id,
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["workflow_phase"] == "plan_review", "Should handle special characters"

    def test_plan_reviewer_handles_many_stages(self, base_state):
        """plan_reviewer should handle plans with many stages."""
        from src.agents.planning import plan_reviewer_node

        stages = [
            {
                "stage_id": f"stage_{i}",
                "stage_type": "SINGLE_STRUCTURE",
                "targets": [f"Fig{i}"],
                "dependencies": [f"stage_{i-1}"] if i > 0 else [],
            }
            for i in range(50)  # 50 stages
        ]

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Many Stages Plan",
            "stages": stages,
            "targets": [{"figure_id": f"Fig{i}"} for i in range(50)],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", "Should handle many stages"

    def test_plan_reviewer_handles_stage_with_many_dependencies(self, base_state):
        """plan_reviewer should handle stages with many dependencies."""
        from src.agents.planning import plan_reviewer_node

        # Create 10 independent stages and one that depends on all of them
        independent_stages = [
            {
                "stage_id": f"independent_{i}",
                "stage_type": "MATERIAL_VALIDATION",
                "targets": [f"mat_{i}"],
                "dependencies": [],
            }
            for i in range(10)
        ]

        dependent_stage = {
            "stage_id": "dependent_on_all",
            "stage_type": "SINGLE_STRUCTURE",
            "targets": ["Fig1"],
            "dependencies": [f"independent_{i}" for i in range(10)],
        }

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Many Dependencies Plan",
            "stages": independent_stages + [dependent_stage],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", "Should handle many dependencies"

    def test_plan_reviewer_handles_stage_with_many_targets(self, base_state):
        """plan_reviewer should handle stages with many targets."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Many Targets Plan",
            "stages": [
                {
                    "stage_id": "stage_0",
                    "stage_type": "PARAMETER_SWEEP",
                    "targets": [f"Fig{i}" for i in range(100)],  # 100 targets
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": f"Fig{i}"} for i in range(100)],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", "Should handle many targets"

    def test_plan_reviewer_handles_diamond_dependency_pattern(self, base_state):
        """plan_reviewer should handle diamond dependency pattern (A->B, A->C, B->D, C->D)."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Diamond Dependencies",
            "stages": [
                {"stage_id": "A", "stage_type": "MATERIAL_VALIDATION", "targets": ["mat"], "dependencies": []},
                {"stage_id": "B", "stage_type": "SINGLE_STRUCTURE", "targets": ["Fig1"], "dependencies": ["A"]},
                {"stage_id": "C", "stage_type": "SINGLE_STRUCTURE", "targets": ["Fig2"], "dependencies": ["A"]},
                {"stage_id": "D", "stage_type": "ARRAY_SYSTEM", "targets": ["Fig3"], "dependencies": ["B", "C"]},
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}, {"figure_id": "Fig3"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Diamond pattern is valid (no cycles)
        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for diamond pattern (valid), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_detects_complex_cycle(self, base_state):
        """plan_reviewer should detect complex cycle (A->B->C->D->B forms a cycle)."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Complex Cycle",
            "stages": [
                {"stage_id": "A", "stage_type": "MATERIAL_VALIDATION", "targets": ["mat"], "dependencies": []},
                {"stage_id": "B", "stage_type": "SINGLE_STRUCTURE", "targets": ["Fig1"], "dependencies": ["A", "D"]},  # D->B creates cycle
                {"stage_id": "C", "stage_type": "SINGLE_STRUCTURE", "targets": ["Fig2"], "dependencies": ["B"]},
                {"stage_id": "D", "stage_type": "ARRAY_SYSTEM", "targets": ["Fig3"], "dependencies": ["C"]},
            ],
            "targets": [{"figure_id": "Fig1"}, {"figure_id": "Fig2"}, {"figure_id": "Fig3"}],
        }

        result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for complex cycle, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "circular" in feedback.lower() or "cycle" in feedback.lower(), (
            f"Feedback should mention cycle, got: {feedback}"
        )

    def test_plan_reviewer_handles_whitespace_in_stage_id(self, base_state):
        """plan_reviewer should handle stages with whitespace-only IDs as missing."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Whitespace ID Plan",
            "stages": [
                {
                    "stage_id": "   ",  # Whitespace only - should be treated as missing
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        result = plan_reviewer_node(base_state)

        # The component checks `if not stage_id:` which is falsy for empty strings
        # But "   " is truthy, so this may pass - testing actual behavior
        # If it should be treated as missing, the component needs to be fixed
        # This test documents actual behavior
        assert result["workflow_phase"] == "plan_review", "Should complete without crashing"

    def test_plan_reviewer_handles_unicode_in_stage_id(self, base_state):
        """plan_reviewer should handle unicode characters in stage IDs."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Unicode ID Plan",
            "stages": [
                {
                    "stage_id": "stage_",  # Chinese characters
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["workflow_phase"] == "plan_review", "Should handle unicode in IDs"

    def test_plan_reviewer_handles_integer_stage_id(self, base_state):
        """plan_reviewer should handle integer stage_id (type coercion edge case)."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Integer ID Plan",
            "stages": [
                {
                    "stage_id": 123,  # Integer instead of string
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [{"figure_id": "Fig1"}],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Integer 123 is truthy so `if not stage_id` won't catch it
        # Test documents actual behavior
        assert result["workflow_phase"] == "plan_review", "Should handle integer IDs"

    def test_plan_reviewer_handles_stage_list_not_a_list(self, base_state):
        """plan_reviewer should handle stages being a dict instead of list."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Bad Stages Type",
            "stages": {"stage_0": {"stage_type": "MATERIAL_VALIDATION", "targets": ["Fig1"]}},  # Dict instead of list
            "targets": [],
        }

        result = plan_reviewer_node(base_state)

        # Dict is truthy and has len() > 0, but iteration will yield keys not dicts
        # The component should handle this gracefully
        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for invalid stages structure, got '{result['last_plan_review_verdict']}'"
        )


class TestPrecisionValidation:
    """Test precision validation for targets requiring digitized data."""

    def test_plan_reviewer_rejects_excellent_precision_without_digitized_data(self, base_state):
        """plan_reviewer should reject targets with excellent precision but no digitized data."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "High Precision Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [
                {
                    "figure_id": "Fig1",
                    "precision_requirement": "excellent",  # <2% requires digitized data
                    # No digitized_data_path - should be rejected
                }
            ],
        }

        result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for excellent precision without digitized data, got '{result['last_plan_review_verdict']}'"
        )
        feedback = result.get("planner_feedback", "")
        assert "precision" in feedback.lower() or "digitized" in feedback.lower() or "excellent" in feedback.lower(), (
            f"Feedback should mention precision/digitized data issue, got: {feedback}"
        )

    def test_plan_reviewer_accepts_excellent_precision_with_digitized_data(self, base_state):
        """plan_reviewer should accept targets with excellent precision when digitized data is provided."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "High Precision Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [
                {
                    "figure_id": "Fig1",
                    "precision_requirement": "excellent",
                    "digitized_data_path": "/path/to/data.csv",  # Has digitized data
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for excellent precision with digitized data, got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_accepts_good_precision_without_digitized_data(self, base_state):
        """plan_reviewer should accept targets with good precision without digitized data (warning only)."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Medium Precision Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [
                {
                    "figure_id": "Fig1",
                    "precision_requirement": "good",  # 5% - warning but not blocking
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        # Should not be blocked - "good" precision is just a warning
        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for good precision (warning only), got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_handles_multiple_precision_issues(self, base_state):
        """plan_reviewer should detect multiple precision issues in one plan."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Multiple Precision Issues",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1", "Fig2", "Fig3"],
                    "dependencies": [],
                }
            ],
            "targets": [
                {"figure_id": "Fig1", "precision_requirement": "excellent"},  # Blocking
                {"figure_id": "Fig2", "precision_requirement": "excellent"},  # Blocking
                {"figure_id": "Fig3", "precision_requirement": "good"},  # Warning only
            ],
        }

        result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "needs_revision", (
            f"Expected 'needs_revision' for multiple blocking precision issues, got '{result['last_plan_review_verdict']}'"
        )

    def test_plan_reviewer_accepts_default_precision(self, base_state):
        """plan_reviewer should accept targets without explicit precision_requirement."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Default Precision Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "SINGLE_STRUCTURE",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
            "targets": [
                {
                    "figure_id": "Fig1",
                    # No precision_requirement - defaults to "good"
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            result = plan_reviewer_node(base_state)

        assert result["last_plan_review_verdict"] == "approve", (
            f"Expected 'approve' for default precision, got '{result['last_plan_review_verdict']}'"
        )


class TestSystemPromptConstruction:
    """Test system prompt construction for plan_reviewer."""

    def test_plan_reviewer_uses_build_agent_prompt(self, base_state):
        """plan_reviewer should use build_agent_prompt to construct system prompt."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ) as mock_call:
            with patch("src.agents.planning.build_agent_prompt", return_value="TEST_PROMPT") as mock_build:
                plan_reviewer_node(base_state)

        # Verify build_agent_prompt was called with correct arguments
        mock_build.assert_called_once()
        call_args = mock_build.call_args
        assert call_args[0][0] == "plan_reviewer", (
            f"Expected build_agent_prompt called with 'plan_reviewer', got '{call_args[0][0]}'"
        )

    def test_plan_reviewer_passes_state_to_build_agent_prompt(self, base_state):
        """plan_reviewer should pass state to build_agent_prompt for prompt adaptations."""
        from src.agents.planning import plan_reviewer_node

        base_state["plan"] = {
            "paper_id": "test",
            "title": "Test Plan",
            "stages": [
                {
                    "stage_id": "s1",
                    "stage_type": "MATERIAL_VALIDATION",
                    "targets": ["Fig1"],
                    "dependencies": [],
                }
            ],
        }
        base_state["prompt_adaptations"] = [{"agent": "plan_reviewer", "adaptation": "Be more strict"}]

        mock_response = {"verdict": "approve", "issues": [], "summary": "OK"}

        with patch(
            "src.agents.planning.call_agent_with_metrics", return_value=mock_response
        ):
            with patch("src.agents.planning.build_agent_prompt", return_value="TEST_PROMPT") as mock_build:
                plan_reviewer_node(base_state)

        # Verify state was passed
        call_args = mock_build.call_args
        passed_state = call_args[0][1]
        assert "prompt_adaptations" in passed_state, "State should contain prompt_adaptations"

